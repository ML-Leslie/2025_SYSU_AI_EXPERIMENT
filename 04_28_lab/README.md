## ðŸ“Œç›®å½•
- [ðŸ“Œç›®å½•](#ç›®å½•)
- [äººå·¥æ™ºèƒ½å®žéªŒæŠ¥å‘Š å®žéªŒäº” æ·±åº¦å­¦ä¹ ](#äººå·¥æ™ºèƒ½å®žéªŒæŠ¥å‘Š-å®žéªŒäº”-æ·±åº¦å­¦ä¹ )
  - [ä¸€ã€å®žéªŒç›®çš„](#ä¸€å®žéªŒç›®çš„)
  - [äºŒã€å®žéªŒå†…å®¹](#äºŒå®žéªŒå†…å®¹)
    - [1. ç®—æ³•åŽŸç†](#1-ç®—æ³•åŽŸç†)
    - [2. å…³é”®ä»£ç å±•ç¤º](#2-å…³é”®ä»£ç å±•ç¤º)
      - [1. æ•°æ®é¢„å¤„ç†](#1-æ•°æ®é¢„å¤„ç†)
      - [2. æ•°æ®åŠ è½½](#2-æ•°æ®åŠ è½½)
      - [3. å®šä¹‰æ¨¡åž‹](#3-å®šä¹‰æ¨¡åž‹)
      - [4. å®žä¾‹åŒ–æ¨¡åž‹](#4-å®žä¾‹åŒ–æ¨¡åž‹)
      - [5. è®­ç»ƒæ¨¡åž‹\&æµ‹è¯•æ¨¡åž‹](#5-è®­ç»ƒæ¨¡åž‹æµ‹è¯•æ¨¡åž‹)
      - [6. ä¸»å‡½æ•°](#6-ä¸»å‡½æ•°)
      - [7. ç”»å›¾éƒ¨åˆ†](#7-ç”»å›¾éƒ¨åˆ†)
    - [3. åˆ›æ–°ç‚¹\&ä¼˜åŒ–](#3-åˆ›æ–°ç‚¹ä¼˜åŒ–)
  - [ä¸‰ã€å®žéªŒç»“æžœåŠåˆ†æž](#ä¸‰å®žéªŒç»“æžœåŠåˆ†æž)
    - [å®žéªŒç»“æžœ](#å®žéªŒç»“æžœ)
    - [åˆ†æž](#åˆ†æž)
      - [æŸå¤±æ›²çº¿](#æŸå¤±æ›²çº¿)
      - [å‡†ç¡®çŽ‡æ›²çº¿](#å‡†ç¡®çŽ‡æ›²çº¿)
    - [æ€»ç»“](#æ€»ç»“)
  - [å››ã€å‚è€ƒæ–‡çŒ®](#å››å‚è€ƒæ–‡çŒ®)

---

## äººå·¥æ™ºèƒ½å®žéªŒæŠ¥å‘Š å®žéªŒäº” æ·±åº¦å­¦ä¹ 
### ä¸€ã€å®žéªŒç›®çš„
- ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¡†æž¶ï¼ˆPytorchï¼‰å®žçŽ°å·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰æ¨¡åž‹ï¼Œå®Œæˆå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚ï¼ˆä¸­è¯å›¾åƒæ•°æ®é›†ï¼‰
- äº†è§£å·ç§¯ç¥žç»ç½‘ç»œçš„åŸºæœ¬åŽŸç†ï¼ŒæŽŒæ¡å·ç§¯ç¥žç»ç½‘ç»œçš„åŸºæœ¬ç»“æž„å’Œè®­ç»ƒæ–¹æ³•ã€‚
### äºŒã€å®žéªŒå†…å®¹
#### 1. ç®—æ³•åŽŸç†
> - å·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰æ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡åž‹ï¼Œä¸»è¦ç”¨äºŽå›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚å®ƒé€šè¿‡å·ç§¯å±‚ã€æ± åŒ–å±‚å’Œå…¨è¿žæŽ¥å±‚ç­‰ç»“æž„æ¥æå–å›¾åƒç‰¹å¾ï¼Œå¹¶è¿›è¡Œåˆ†ç±»æˆ–å›žå½’ç­‰ä»»åŠ¡ã€‚
> - å·ç§¯å±‚ï¼šé€šè¿‡å·ç§¯æ ¸å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå·ç§¯æ“ä½œï¼Œæå–å±€éƒ¨ç‰¹å¾ã€‚
> - æ± åŒ–å±‚ï¼šå¯¹å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾è¿›è¡Œä¸‹é‡‡æ ·ï¼Œå‡å°‘ç‰¹å¾å›¾çš„å°ºå¯¸ï¼Œé™ä½Žè®¡ç®—å¤æ‚åº¦ã€‚
> - å…¨è¿žæŽ¥å±‚ï¼šå°†å·ç§¯å±‚å’Œæ± åŒ–å±‚æå–çš„ç‰¹å¾è¿›è¡Œæ•´åˆï¼Œè¾“å‡ºæœ€ç»ˆçš„åˆ†ç±»ç»“æžœã€‚
- å…·ä½“åˆ°å®žçŽ°ï¼š
  - æ•°æ®é¢„å¤„ç†
    - æ•°æ®é›†åˆ’åˆ†å·²åœ¨æä¾›çš„æ•°æ®é›†ä¸­å®Œæˆ
    - æ•°æ®å¢žå¼ºï¼šå¯¹è®­ç»ƒé›†å›¾åƒè¿›è¡Œï¼Œé¢œè‰²æŠ–åŠ¨ä¸Žæ ‡å‡†åŒ–
  - æ•°æ®åŠ è½½
    - æ ¹æ®è®¾å®šçš„ [BATCH_SIZE]() åŠ è½½æ•°æ®é›†ï¼Œè®¾ç½®éšæœºæ‰“ä¹±ç­‰å‚æ•°
  - å®šä¹‰æ¨¡åž‹
    - ç»§æ‰¿ `torch.nn.Module` å®šä¹‰å·ç§¯ç¥žç»ç½‘ç»œæ¨¡åž‹
    - è¿™é‡Œå®šä¹‰äº”ä¸ªå·ç§¯å±‚ï¼ˆæ¯ä¸€å±‚ç»è¿‡æ¿€æ´»å‡½æ•°åŠæ± åŒ–ï¼‰+ å…¨è¿žæŽ¥å±‚
  - å®žä¾‹åŒ–æ¨¡åž‹
    - å®žä¾‹åŒ–æ¨¡åž‹ï¼Œå®šä¹‰æŸå¤±å‡½æ•°ï¼ˆäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼‰ï¼Œä¼˜åŒ–å™¨ï¼ˆAdamä¼˜åŒ–å™¨ï¼‰
  - è®­ç»ƒæ¨¡åž‹
    - ä»Žæ•°æ®åŠ è½½å™¨é‡Œé¢æ ¹æ®è®¾å®šæ‰¹æ¬¡åŠ è½½æ•°æ®ï¼Œè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè®¡ç®—æŸå¤±å‡½æ•°ï¼Œåå‘ä¼ æ’­æ›´æ–°å‚æ•°
    - æ¯ä¸€æ¬¡è¿­ä»£åŽå±•ç¤ºæ€»çš„æŸå¤±çŽ‡å’Œå‡†ç¡®çŽ‡
  - æµ‹è¯•æ¨¡åž‹
    - åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè®¡ç®—å‡†ç¡®çŽ‡å’ŒæŸå¤±çŽ‡
- ç”»å›¾éƒ¨åˆ†è§ â†“ [å…³é”®ä»£ç å±•ç¤º](#2-å…³é”®ä»£ç å±•ç¤º)
#### 2. å…³é”®ä»£ç å±•ç¤º
##### 1. æ•°æ®é¢„å¤„ç†
```py
# æ•°æ®é¢„å¤„ç†
train_transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2), # éšæœºé¢œè‰²æŠ–åŠ¨
    transforms.ToTensor(), 
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # æ ‡å‡†åŒ–
])

test_transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(), 
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # æ ‡å‡†åŒ–
])


data_dir = 'cnn'
train_dir = os.path.join(data_dir, 'train')
test_dir = os.path.join(data_dir, 'test')

train_dataset = ImageFolder(root=train_dir, transform=train_transform)
test_dataset = ImageFolder(root=test_dir, transform=test_transform)
```
- å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å¤„ç†ä¸åŒï¼Œè®­ç»ƒé›†é‡‡ç”¨é¢œè‰²æŠ–åŠ¨åŠæ ‡å‡†åŒ–å¤„ç†ï¼Œæµ‹è¯•é›†åªè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
- ç„¶åŽè®¾ç½®è·¯å¾„å°†å›¾ç‰‡ä¼ å…¥ `ImageFolder`ï¼ˆåŠ è½½å›¾åƒæ•°æ®é›†çš„ç±»ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ ¹æ®æ–‡ä»¶å¤¹ç»“æž„æ¥åŠ è½½æ•°æ®ï¼‰ ä¸­ï¼ŒèŽ·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†
- è¿™é‡Œçš„ `ImageFolder` éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ•°æ®é›†çš„æ–‡ä»¶å¤¹ç»“æž„å¿…é¡»æ˜¯è¿™æ ·çš„ï¼š
    ```bash
    cnn
    â”œâ”€â”€ test
    â”‚   â”œâ”€â”€ baihe
    â”‚   â”‚   â”œâ”€â”€ *.jpg
    â”‚   â”‚   â”œâ”€â”€ ...
    â”‚   â”œâ”€â”€ dangshen
    â”‚   â”‚   â”œâ”€â”€ *.jpg
    â”‚   â”‚   â”œâ”€â”€ ...
    â”‚   â”œâ”€â”€ ...
    â”‚   
    â””â”€â”€ train
        â”œâ”€â”€ baihe
        â”‚   â”œâ”€â”€ *.jpg
        â”‚   â”œâ”€â”€ ...
        â”œâ”€â”€ dangshen
        â”‚   â”œâ”€â”€ *.jpg
        â”‚   â”œâ”€â”€ ...
        â”œâ”€â”€ ...
    ```
##### 2. æ•°æ®åŠ è½½
```py
train_loader = torch.utils.data.DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=0, 
    pin_memory=True) 
test_loader = torch.utils.data.DataLoader(
    test_dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=False, num_workers=0, 
    pin_memory=True)
```
- è¿™é‡Œçš„ `DataLoader` æ˜¯ PyTorch ä¸­ç”¨äºŽåŠ è½½æ•°æ®çš„ç±»ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å°†æ•°æ®é›†åˆ’åˆ†ä¸ºæ‰¹æ¬¡ï¼Œå¹¶è¿›è¡Œéšæœºæ‰“ä¹±ç­‰æ“ä½œ
- è®¾ç½® `BATCH_SIZE` ä¸º 32ï¼Œè¡¨ç¤ºæ¯ä¸ªæ‰¹æ¬¡åŠ è½½ 32 å¼ å›¾ç‰‡
- å¯¹äºŽè®­ç»ƒé›†ï¼Œè®¾ç½® `shuffle=True`ï¼Œè¡¨ç¤ºæ¯ä¸ª epoch è®­ç»ƒæ—¶éšæœºæ‰“ä¹±æ•°æ®é¡ºåºï¼ˆéšæœºæ‰“ä¹±æ•°æ®å¯ä»¥æé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ï¼‰ï¼Œå¯¹äºŽæµ‹è¯•é›†åˆ™ä¸è¿›è¡Œæ‰“ä¹±
##### 3. å®šä¹‰æ¨¡åž‹
```py
# å®šä¹‰ç½‘ç»œæ¨¡åž‹
class myCNN(nn.Module):
    def __init__(self, num_classes = 5):
        
        super(myCNN, self).__init__()

        # ç¬¬ä¸€ä¸ªå·ç§¯å—
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # ç¬¬äºŒä¸ªå·ç§¯å—
        self.conv2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # ç¬¬ä¸‰ä¸ªå·ç§¯å—
        self.conv3 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # ç¬¬å››ä¸ªå·ç§¯å—
        self.conv4 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # ç¬¬äº”ä¸ªå·ç§¯å—
        self.conv5 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
            
        # å®šä¹‰å…¨è¿žæŽ¥å±‚
        self.fc_input_size = 512 * 7 * 7


        self.fc = nn.Sequential(
            nn.Linear(self.fc_input_size, 1024),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )

        # åˆå§‹åŒ–æƒé‡
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, mean=0, std=0.01)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = x.view(x.size(0), -1)  # å±•å¹³
        self.fc_input_size = x.size(1)
        x = self.fc(x)
        return x
```
- è¿™é‡Œå®šä¹‰äº†ä¸€ä¸ªå·ç§¯ç¥žç»ç½‘ç»œæ¨¡åž‹ `myCNN`ï¼ŒåŒ…å«äº”ä¸ªå·ç§¯å—å’Œå…¨è¿žæŽ¥å±‚ï¼Œæ¯ä¸ªå·ç§¯å—ç”±å·ç§¯å±‚ã€æ¿€æ´»å‡½æ•°ï¼ˆReLUï¼‰å’Œæ± åŒ–å±‚ç»„æˆ
- ä»¥ç¬¬ä¸€ä¸ªå·ç§¯å—ä¸ºä¾‹ï¼š
  - `nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)`ï¼šè¾“å…¥é€šé“æ•°ä¸º 3ï¼ˆRGB å›¾åƒï¼‰ï¼Œè¾“å‡ºé€šé“æ•°ä¸º 32ï¼Œå·ç§¯æ ¸å¤§å°ä¸º 3x3ï¼Œæ­¥é•¿ä¸º 1ï¼Œpadding ä¸º 1ï¼ˆä¿æŒå›¾åƒå¤§å°ä¸å˜ï¼‰
    ![conv](http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif)
    - *å›¾æº [Convolution_schematic](http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/)*
  - `nn.ReLU()`ï¼šæ¿€æ´»å‡½æ•°ï¼Œå¢žåŠ éžçº¿æ€§  $f(x) = max(0 ,x)$ 
  - `nn.MaxPool2d(kernel_size=2, stride=2)`ï¼šæ± åŒ–å±‚ï¼Œæ± åŒ–æ ¸å¤§å°ä¸º 2x2ï¼Œæ­¥é•¿ä¸º 2ï¼ˆä¸‹é‡‡æ ·ï¼‰
    - ä»€ä¹ˆå«ä¸‹é‡‡æ ·ï¼Ÿé€šè¿‡æ± åŒ–æ“ä½œï¼Œå‡å°‘ç‰¹å¾å›¾çš„å°ºå¯¸ï¼Œé™ä½Žè®¡ç®—å¤æ‚åº¦ï¼ˆå¦‚æžœç›´æŽ¥ä½¿ç”¨å·ç§¯å±‚ï¼Œç‰¹å¾å›¾çš„å°ºå¯¸ä¼šå˜å¾—å¾ˆå¤§ï¼Œå¯¹è®¡ç®—èµ„æºçš„è´Ÿæ‹…å¾ˆå¤§ï¼Œä¹Ÿå®¹æ˜“è¿‡æ‹Ÿåˆï¼Œæ‰€ä»¥è€ƒè™‘è®¡ç®—å›¾åƒæŸä¸ªåŒºåŸŸä¸Šç‰¹å®šç‰¹å¾çš„å¹³å‡å€¼ï¼ˆæˆ–æœ€å¤§å€¼ï¼‰ï¼Œè¿™æ ·æ±‡æ€»çš„ç»Ÿè®¡æ•°æ®ç»´åº¦ä¼šå°å¾ˆå¤šï¼‰
      ![pooling](http://ufldl.stanford.edu/tutorial/images/Pooling_schematic.gif)
      - *å›¾æº [Pooling_schematic](http://ufldl.stanford.edu/tutorial/supervised/Pooling/)*
- å…¨è¿žæŽ¥å±‚ï¼š`self.fc = nn.Sequential(...)`ï¼ŒåŒ…å«ä¸‰ä¸ªå…¨è¿žæŽ¥å±‚ï¼Œä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°å’Œ Dropoutï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
##### 4. å®žä¾‹åŒ–æ¨¡åž‹
```py
# å®žä¾‹åŒ–æ¨¡åž‹ï¼Œå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
model = myCNN(num_classes=len(train_dataset.classes)).to(device)
criterion = nn.CrossEntropyLoss() # äº¤å‰ç†µæŸå¤±å‡½æ•° 
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # Adamä¼˜åŒ–å™¨ 
```
- æŸå¤±å‡½æ•°ï¼šä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆ`nn.CrossEntropyLoss()`ï¼‰ï¼Œåœ¨å¤šåˆ†ç±»é—®é¢˜ä¸­å¸¸ç”¨ã€‚å…¶ä¸­ $y$  ä¸ºçœŸå®žæ ‡ç­¾ï¼Œ$\hat{y}$ ä¸ºé¢„æµ‹å€¼ï¼Œ$N$ ä¸ºæ ·æœ¬æ•°ï¼Œ $C$ ä¸ºç±»åˆ«æ•°ï¼Œ $y_{ij}$ ä¸ºç¬¬ $i$ ä¸ªæ ·æœ¬çš„ç¬¬ $j$ ä¸ªç±»åˆ«çš„çœŸå®žæ ‡ç­¾ï¼ˆone-hot ç¼–ç ï¼‰ï¼Œ$\hat{y}_{ij}$ ä¸ºç¬¬ $i$ ä¸ªæ ·æœ¬çš„ç¬¬ $j$ ä¸ªç±»åˆ«çš„é¢„æµ‹å€¼
```math
L(y, \hat{y}) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{C} y_{ij} \log(\hat{y}_{ij}) \\
```
- ä¼˜åŒ–å™¨ï¼šä¼˜åŒ–å™¨çš„ä½œç”¨æ˜¯æ›´æ–°æ¨¡åž‹çš„å‚æ•°ï¼Œä½¿å¾—æŸå¤±å‡½æ•°æœ€å°åŒ–ã€‚è¿™é‡Œä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼ˆ`optim.Adam()`ï¼‰ï¼Œå®ƒæ˜¯ä¸€ç§è‡ªé€‚åº”å­¦ä¹ çŽ‡ä¼˜åŒ–ç®—æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®æ¯ä¸ªå‚æ•°çš„åŽ†å²æ¢¯åº¦ä¿¡æ¯è‡ªåŠ¨è°ƒæ•´å­¦ä¹ çŽ‡
##### 5. è®­ç»ƒæ¨¡åž‹&æµ‹è¯•æ¨¡åž‹
- è®­ç»ƒæ¨¡åž‹å’Œæµ‹è¯•æ¨¡åž‹çš„å¤§ä½“æ€ç»´ç›¸ä¼¼
    ```py
    # è®­ç»ƒå‡½æ•°
    def train(model, train_loader, criterion, optimizer, device):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # åå‘ä¼ æ’­
            loss.backward() 
            optimizer.step() # æ›´æ–°å‚æ•°
        
            # è®¡ç®—æŸå¤±å’Œå‡†ç¡®çŽ‡
            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = correct / total

        return epoch_loss, epoch_acc

    def test(model, test_loader, criterion, device):
        model.eval()
        running_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)

                # å‰å‘ä¼ æ’­
                outputs = model(images)
                loss = criterion(outputs, labels)

                # è®¡ç®—æŸå¤±å’Œå‡†ç¡®çŽ‡
                running_loss += loss.item() * images.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        epoch_loss = running_loss / len(test_loader.dataset)
        epoch_acc = correct / total

        return epoch_loss, epoch_acc
    ```
- æŸå¤±çŽ‡çš„è®¡ç®—ï¼š
    - `running_loss += loss.item() * images.size(0)`ï¼šå°†æ¯ä¸ªæ‰¹æ¬¡çš„æŸå¤±ä¹˜ä»¥æ‰¹æ¬¡å¤§å°ï¼Œç´¯åŠ åˆ° `running_loss` ä¸­
    - `epoch_loss = running_loss / len(train_loader.dataset)`ï¼šå°†æ€»æŸå¤±é™¤ä»¥æ•°æ®é›†å¤§å°ï¼Œå¾—åˆ°å¹³å‡æŸå¤±çŽ‡
- å‡†ç¡®çŽ‡çš„è®¡ç®—ï¼š
  - `_, predicted = torch.max(outputs.data, 1)`ï¼šé€šè¿‡åˆ—æ–¹å‘å¯»æ‰¾æ¯ä¸ªæ ‡ç­¾çš„é¢„æµ‹å€¼çš„æœ€å¤§å€¼ï¼ŒèŽ·å–æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç±»åˆ«ï¼ˆè¿”å›žå€¼æ˜¯ä¸€ä¸ªå…ƒç»„(æœ€å¤§å€¼ï¼Œç´¢å¼•)ï¼Œè¿™é‡Œåªéœ€è¦ç´¢å¼•ï¼‰
  - `total += labels.size(0)`ï¼šç´¯åŠ æ€»æ ·æœ¬æ•°
  - `correct += (predicted == labels).sum().item()`ï¼šç´¯åŠ é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
  - `epoch_acc = correct / total`ï¼šè®¡ç®—å¹³å‡å‡†ç¡®çŽ‡
- æµ‹è¯•å‡½æ•°ä¸­çš„ `with torch.no_grad()`ï¼šç”±äºŽæµ‹è¯•ä¸éœ€è¦åå‘ä¼ æ’­ï¼Œæ‰€ä»¥ä½¿ç”¨ `torch.no_grad()` æ¥å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œè¿™æ ·å¯ä»¥èŠ‚çœå†…å­˜å’Œè®¡ç®—èµ„æº
##### 6. ä¸»å‡½æ•°
```py
if __name__ == "__main__":

    # å…¶å®ƒä»£ç ...

    for epoch in range(TRAIN_EPOCHS):
            # è®­ç»ƒ
            train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)
            train_losses.append(train_loss)
            train_accuracies.append(train_acc)

            # æµ‹è¯•
            test_loss, test_acc = test(model, test_loader, criterion, device)
            test_losses.append(test_loss)
            test_accuracies.append(test_acc)

            # ä¿å­˜æœ€ä½³æ¨¡åž‹
            if test_acc > best_acc:
                best_acc = test_acc
                torch.save(model.state_dict(), 'best_model.pth')
                print(f"ä¿å­˜æœ€ä½³æ¨¡åž‹ï¼Œå‡†ç¡®çŽ‡: {best_acc:.4f}")
            
            # æ‰“å°è®­ç»ƒå’Œæµ‹è¯•ç»“æžœ
            print(f"Epoch [{epoch+1}/{TRAIN_EPOCHS}], "
                f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
                f"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}")
            

        end_time = time.time()
        print(f"è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"æœ€ä½³æµ‹è¯•å‡†ç¡®çŽ‡: {best_acc:.4f}")

    # ç”»å›¾éƒ¨åˆ†...
```
- è®­ç»ƒå’Œæµ‹è¯•å‡½æ•°çš„è°ƒç”¨åœ¨ä¸»å‡½æ•°ä¸­è¿›è¡Œï¼Œä½¿ç”¨ `for` å¾ªçŽ¯è¿›è¡Œå¤šæ¬¡è¿­ä»£ï¼ˆepochï¼‰ï¼Œæ¯æ¬¡è¿­ä»£éƒ½è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•
- `train_losses` å’Œ `train_accuracies` ç”¨äºŽå­˜å‚¨æ¯ä¸ª epoch çš„è®­ç»ƒæŸå¤±å’Œå‡†ç¡®çŽ‡ï¼Œ`test_losses` å’Œ `test_accuracies` ç”¨äºŽå­˜å‚¨æ¯ä¸ª epoch çš„æµ‹è¯•æŸå¤±å’Œå‡†ç¡®çŽ‡
- `best_acc` ç”¨äºŽä¿å­˜æœ€ä½³æµ‹è¯•å‡†ç¡®çŽ‡ï¼Œä¸€æ—¦æœ‰æ–°çš„æœ€ä½³å‡†ç¡®çŽ‡ï¼Œå°±ä¿å­˜æ¨¡åž‹å‚æ•°åˆ° `best_model.pth` æ–‡ä»¶ä¸­ï¼ŒåŽç»­ç”»å›¾æ—¶ä½¿ç”¨
##### 7. ç”»å›¾éƒ¨åˆ†
```py
if __name__ == "__main__":

    # å…¶å®ƒä»£ç ...

    # åŠ è½½æœ€ä½³æ¨¡åž‹
    model.load_state_dict(torch.load('best_model.pth'))

    # ç»˜åˆ¶å›¾è¡¨
    plt.figure(figsize=(12, 5))

    # æŸå¤±æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(test_losses, label='Test Loss')
    plt.title('Loss Curve')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # å‡†ç¡®çŽ‡æ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(train_accuracies, label='Train Accuracy')
    plt.plot(test_accuracies, label='Test Accuracy')
    plt.title('Accuracy Curve')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.savefig('training_curve.svg')
    plt.show()

    # æ¨¡åž‹è¯„ä¼°å±•ç¤º
    images, labels = next(iter(test_loader))
    images, labels = images.to(device), labels.to(device)

    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)

    # æ•°æ®è¿å›žCPU
    images = images.cpu()
    labels = labels.cpu()
    predicted = predicted.cpu()

    # èŽ·å–ç±»åˆ«
    classes_names = test_dataset.classes

    # æ˜¾ç¤ºå›¾ç‰‡å’Œé¢„æµ‹ç»“æžœ
    num_images = 10
    images_pre_row = num_images // 2
    num_rows = 2

    plt.figure(figsize=(15, 6))
    for i in range(num_images):
        plt.subplot(num_rows, images_pre_row, i + 1)
        plt.imshow(images[i].permute(1, 2, 0).numpy())
        plt.title(f"Act: {classes_names[labels[i]]}\nPre: {classes_names[predicted[i]]}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()
    plt.savefig('predictions.svg')
```
- ä¸»è¦æœ‰ä¸¤ä¸ªå›¾ï¼šç¬¬ä¸€ä¸ªå›¾åŒ…æ‹¬ä¸¤ä¸ªå­å›¾ï¼šæŸå¤±çŽ‡æ›²çº¿å’Œå‡†ç¡®çŽ‡æ›²çº¿ï¼Œç¬¬äºŒä¸ªå›¾æ˜¯æ¨¡åž‹è¯„ä¼°å±•ç¤ºï¼Œæ˜¾ç¤ºäº†æµ‹è¯•é›†ä¸Šå‰ 10 å¼ å›¾ç‰‡çš„çœŸå®žæ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
#### 3. åˆ›æ–°ç‚¹&ä¼˜åŒ–
- ä½¿ç”¨è°ƒåº¦å™¨ï¼ˆ`StepLR` æˆ–è€… `ReduceLROnPlateau`ï¼‰æ¥è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œæé«˜æ¨¡åž‹çš„æ”¶æ•›é€Ÿåº¦å’Œå‡†ç¡®çŽ‡
- æ•°æ®å¤„ç†çš„æ—¶å€™åŠ å…¥äº†é¢œè‰²æŠ–åŠ¨ï¼ˆ`ColorJitter`ï¼‰ï¼Œå¯¹æµ‹è¯•é›†çš„è®­ç»ƒç»“æžœæ›´å¥½
- åˆ›å»ºåŠ è½½å™¨çš„æ—¶å€™è®¾ç½®äº† `pin_memory=True`ï¼Œå¯ä»¥åŠ é€Ÿæ•°æ®åŠ è½½
### ä¸‰ã€å®žéªŒç»“æžœåŠåˆ†æž
#### å®žéªŒç»“æžœ
> - è®­ç»ƒå‚æ•°ï¼š
>   - æ‰¹æ¬¡å¤§å°ï¼š32
>   - å­¦ä¹ çŽ‡ï¼š0.001
>   - è®­ç»ƒè½®æ•°ï¼š30
> - æ­¤å¤„å±•ç¤ºæœ€ä¼˜å®žéªŒç»“æžœ
- æœ€ä½³ç»“æžœï¼š`Epoch [29/30], Train Loss: 0.1162, Train Acc: 0.9557, Test Loss: 0.0213, Test Acc: 1.0000`
- æ›²çº¿ï¼š
    ![](images/training_curve1.svg)
- ç»“æžœå±•ç¤ºï¼š
    ![](images/image.png)
#### åˆ†æž
##### æŸå¤±æ›²çº¿
- è®­ç»ƒæŸå¤±çŽ‡å’Œæµ‹è¯•æŸå¤±çŽ‡éƒ½éšç€è¿­ä»£æ¬¡æ•°çš„å¢žåŠ è€Œé€æ¸å‡å°ï¼Œè¯´æ˜Žæ¨¡åž‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å­¦ä¹ åˆ°äº†æ•°æ®çš„ç‰¹å¾
- è®­ç»ƒé›†æŸå¤±çŽ‡çš„æ³¢åŠ¨è¾ƒæµ‹è¯•é›†çš„å°ï¼Œæµ‹è¯•é›†ç”±äºŽåªæœ‰ 10 å¼ å›¾ç‰‡ï¼Œæ‰€ä»¥æ³¢åŠ¨è¾ƒå¤§
- åœ¨æŽ¥è¿‘è¿­ä»£æ¬¡æ•° 30 æ—¶ï¼Œå‘ç”Ÿå›žå‡ï¼Œè¯´æ˜Žæ¨¡åž‹å¯èƒ½å‡ºçŽ°äº†è¿‡æ‹ŸåˆçŽ°è±¡ï¼Œæ‰€ä»¥å‰é¢å°†è®­ç»ƒè½®æ•°è®¾ç½®ä¸º 30 æ¬¡
##### å‡†ç¡®çŽ‡æ›²çº¿
- å¯ä»¥çœ‹åˆ°è®­ç»ƒé›†çš„å‡†ç¡®çŽ‡æ›²çº¿ä¸Šå‡éžå¸¸å®Œç¾Žï¼Œè¯´æ˜Žæ¨¡åž‹åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆå¾—å¾ˆå¥½
- æµ‹è¯•é›†çš„å‡†ç¡®çŽ‡æ›²çº¿ä¹Ÿåœ¨é€æ¸ä¸Šå‡ï¼Œä½†æ˜¯æ³¢åŠ¨å¾ˆå¤§ï¼Œæ€è€ƒæ˜¯å› ä¸ºæµ‹è¯•é›†åªæœ‰ 10 å¼ å›¾ç‰‡ï¼Œå‡†ç¡®çŽ‡åªæœ‰ 10 ä¸ªæ•°å€¼ï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯æ‰¹æ¬¡å¤§å°è®¾ç½®å¾—å¤ªå°ï¼Œå¯¼è‡´æ¨¡åž‹åœ¨æµ‹è¯•é›†ä¸Šè¡¨çŽ°ä¸ç¨³å®š
#### æ€»ç»“
- æ•´ä¸ªå®žéªŒä¸­ï¼Œæ¨¡åž‹çš„è®­ç»ƒå’Œæµ‹è¯•ç»“æžœéƒ½æ¯”è¾ƒç†æƒ³ï¼Œå‡†ç¡®çŽ‡è¾¾åˆ°äº† 100%ï¼Œè¯´æ˜Žæ¨¡åž‹åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè¡¨çŽ°è‰¯å¥½
### å››ã€å‚è€ƒæ–‡çŒ®
> - [PyTorch å®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/stable/index.html)
> - http://ufldl.stanford.edu
> - https://data.mendeley.com/datasets/2kjmzjyrmd/3